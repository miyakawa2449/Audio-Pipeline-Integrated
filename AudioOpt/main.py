"""
éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
æ•´ç†ãƒ»å†æ§‹æˆç‰ˆ
"""

import sys
import os
from pathlib import Path

# å®‰å…¨ãªinputé–¢æ•°
def safe_input(prompt, default=""):
    """EOFErrorã«å¯¾å¿œã—ãŸå®‰å…¨ãªinputé–¢æ•°"""
    try:
        return input(prompt)
    except EOFError:
        print(f"\n[è‡ªå‹•å…¥åŠ›] {default}")
        return default
    except KeyboardInterrupt:
        print("\n[ä¸­æ–­ã•ã‚Œã¾ã—ãŸ]")
        return "q"

# Common modules import
sys.path.append(str(Path(__file__).parent.parent / "common"))
try:
    from logger import get_logger
    from error_handler import error_handler, ErrorSeverity, handle_error
    from exceptions import (
        AudioPipelineError, AudioFileError, ModelError, 
        DeviceError, SystemError, AppleSiliconError
    )
except ImportError:
    # Fallback for missing common modules
    import logging
    
    class FallbackLogger:
        def __init__(self, name):
            self.logger = logging.getLogger(name)
            self.logger.setLevel(logging.INFO)
            if not self.logger.handlers:
                handler = logging.StreamHandler()
                handler.setFormatter(logging.Formatter('%(levelname)s | %(message)s'))
                self.logger.addHandler(handler)
        
        def debug(self, msg): self.logger.debug(msg)
        def info(self, msg): self.logger.info(msg)
        def warning(self, msg): self.logger.warning(msg)
        def error(self, msg): self.logger.error(msg)
        def start_operation(self, msg): self.logger.info(f"ğŸš€ {msg} ã‚’é–‹å§‹")
        def complete_operation(self, msg): self.logger.info(f"âœ… {msg} ãŒå®Œäº†")
        def success(self, msg): self.logger.info(f"âœ… {msg}")
        def progress(self, msg): self.logger.info(f"ğŸ”„ {msg}")
        def audio_info(self, msg): self.logger.info(f"ğŸµ {msg}")
        def model_info(self, msg): self.logger.info(f"ğŸ¤– {msg}")
        def device_info(self, msg): self.logger.info(f"ğŸ›ï¸ {msg}")
    
    def get_logger(name): return FallbackLogger(name)
    def error_handler(**kwargs): return lambda f: f
    def handle_error(e, **kwargs): raise e
    ErrorSeverity = type('ErrorSeverity', (), {'MEDIUM': 'medium', 'HIGH': 'high', 'CRITICAL': 'critical'})
    
    class AudioPipelineError(Exception):
        def __init__(self, message, suggestions=None):
            super().__init__(message)
            self.suggestions = suggestions
    
    class AudioFileError(AudioPipelineError): pass
    class ModelError(AudioPipelineError): pass
    class DeviceError(AudioPipelineError): pass
    class SystemError(AudioPipelineError): pass
    class AppleSiliconError(AudioPipelineError): pass

# srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Logger initialization
logger = get_logger("AudioOptMain")

# å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è‡ªå‹•ä½œæˆ
def ensure_directories():
    """AudioOptã«å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    directories = [
        "dataset",
        "dataset/audio_files", 
        "dataset/meta_files",
        "models",
        "output",
        "logs"
    ]
    
    for dir_path in directories:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        logger.debug(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {dir_path}")
    
    logger.success("å¿…è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ")

try:
    from src.core import VoiceCloner
    logger.success("AudioOpt VoiceCloner ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    error = AudioFileError(
        f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}",
        suggestions=(
            "ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:\n"
            "1. srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹\n"
            "2. å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¨ã¦é…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹\n"
            "3. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹"
        )
    )
    handle_error(error, severity=ErrorSeverity.CRITICAL)
    sys.exit(1)

# =============================================================================
# ã‚·ã‚¹ãƒ†ãƒ é–¢é€£æ©Ÿèƒ½
# =============================================================================

@error_handler(severity=ErrorSeverity.HIGH, recovery=True)
def check_dependencies():
    """ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯"""
    logger.start_operation("ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯")
    missing_packages = []
    
    dependencies = [
        ('torch', 'PyTorch'),
        ('torchaudio', 'Torchaudio'),
        ('soundfile', 'Soundfile'),
        ('numpy', 'NumPy')
    ]
    
    for package_name, display_name in dependencies:
        try:
            module = __import__(package_name)
            version = getattr(module, '__version__', 'unknown')
            logger.success(f"{display_name}: {version}")
        except ImportError:
            missing_packages.append(package_name)
            logger.warning(f"{display_name}: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
    
    if missing_packages:
        error = SystemError(
            f"ä¸è¶³ã—ã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {', '.join(missing_packages)}",
            suggestions=f"conda install {' '.join(missing_packages)}"
        )
        handle_error(error, severity=ErrorSeverity.HIGH)
        return False
    
    logger.complete_operation("ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯")
    return True

def display_system_info(cloner):
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¡¨ç¤º"""
    print("\n=== ã‚·ã‚¹ãƒ†ãƒ æƒ…å ± ===")
    print(f"Dataset path: {cloner.dataset_path}")
    print(f"Audio files path: {cloner.audio_path}")
    print(f"Text files path: {cloner.meta_path}")
    print(f"Models path: {cloner.models_path}")
    print(f"Output path: {cloner.output_path}")
    print(f"Device: {cloner.device}")
    
    # GPUæƒ…å ±ã‚’è¡¨ç¤º
    if cloner.device.type == 'cuda':
        try:
            import torch
            gpu_props = torch.cuda.get_device_properties(0)
            logger.info(f"ğŸ® GPU Memory: {gpu_props.total_memory // 1024**3} GB")
            logger.info(f"ğŸ® GPU Name: {gpu_props.name}")
        except Exception as e:
            logger.warning(f"GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
        print(f"Vocabulary size: {len(cloner.text_processor.vocab)}")
    else:
        print("Vocabulary: Not built yet")
    
    if cloner.model is not None:
        print("Model: Loaded")
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¡¨ç¤º
        try:
            total_params = sum(p.numel() for p in cloner.model.parameters())
            logger.info(f"ğŸ¤– Model parameters: {total_params:,}")
        except Exception as e:
            logger.debug(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("Model: Not loaded")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´
# =============================================================================

@error_handler(severity=ErrorSeverity.HIGH, recovery=True)
def train_model_interactive(cloner):
    """å¯¾è©±å¼ã§ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’å®Ÿè¡Œ"""
    logger.start_operation("å¯¾è©±å¼ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    try:
        audio_files, text_files = cloner.collect_data_files()
        if len(audio_files) == 0:
            print("\nâŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("\nğŸ“‹ è©³ç´°è¨ºæ–­:")
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ãƒã‚§ãƒƒã‚¯
            dataset_path = Path("dataset")
            audio_path = dataset_path / "audio_files" 
            meta_path = dataset_path / "meta_files"
            
            print(f"  dataset/: {'âœ… å­˜åœ¨' if dataset_path.exists() else 'âŒ ä¸å­˜åœ¨'}")
            print(f"  audio_files/: {'âœ… å­˜åœ¨' if audio_path.exists() else 'âŒ ä¸å­˜åœ¨'}")
            print(f"  meta_files/: {'âœ… å­˜åœ¨' if meta_path.exists() else 'âŒ ä¸å­˜åœ¨'}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
            if audio_path.exists():
                audio_count = len(list(audio_path.glob("*.wav")))
                print(f"  éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {audio_count}")
            if meta_path.exists():
                text_count = len(list(meta_path.glob("*.txt")))
                print(f"  ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {text_count}")
            
            print("\nğŸ’¡ è§£æ±ºæ–¹æ³•:")
            print("  1. Python_Audio_datasetã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’éŒ²éŸ³ã—ã¦ãã ã•ã„")
            print("  2. ã¾ãŸã¯ã€æ—¢å­˜ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’dataset/audio_files/ã«é…ç½®")
            print("  3. å¯¾å¿œã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’dataset/meta_files/ã«é…ç½®")
            print("  4. ãƒ•ã‚¡ã‚¤ãƒ«åã¯ 'audio_NNNN.wav' ã¨ 'audio_NNNN.txt' ã®å½¢å¼ã§")
            
            return
        
        logger.success(f"{len(audio_files)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        validation_results = validate_dataset_files(audio_files, text_files)
        valid_count = sum(1 for r in validation_results if r['valid'])
        
        if valid_count < len(audio_files):
            print(f"\nâš ï¸ è­¦å‘Š: {len(audio_files) - valid_count}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
            print("è©³ç´°ã¯ãƒ¡ãƒ‹ãƒ¥ãƒ¼5ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªï¼‰ã§ç¢ºèªã—ã¦ãã ã•ã„")
            
            proceed = safe_input("å•é¡ŒãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚ã¦è¨“ç·´ã‚’ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ", "n").strip().lower()
            if proceed != 'y':
                print("è¨“ç·´ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                return
        
    except Exception as e:
        print(f"\nâŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›
    try:
        epochs_input = safe_input("ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å…¥åŠ› (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100): ", "100").strip()
        epochs = int(epochs_input) if epochs_input else 100
        
        if epochs <= 0:
            raise ValueError("ã‚¨ãƒãƒƒã‚¯æ•°ã¯1ä»¥ä¸Šã§å…¥åŠ›ã—ã¦ãã ã•ã„")
            
        batch_size_input = safe_input("ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å…¥åŠ› (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2): ", "2").strip()
        batch_size = int(batch_size_input) if batch_size_input else 2
        
        if batch_size <= 0 or batch_size > len(audio_files):
            raise ValueError(f"ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯1ä»¥ä¸Š{len(audio_files)}ä»¥ä¸‹ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        learning_rate_input = safe_input("å­¦ç¿’ç‡ã‚’å…¥åŠ› (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.001): ", "0.001").strip()
        learning_rate = float(learning_rate_input) if learning_rate_input else 0.001
        
        print(f"\nè¨“ç·´è¨­å®š:")
        print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
        print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
        print(f"  å­¦ç¿’ç‡: {learning_rate}")
        print(f"  ãƒ‡ãƒ¼ã‚¿æ•°: {len(audio_files)}")
        
        confirm = safe_input("\nè¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): ", "n").strip().lower()
        if confirm != 'y':
            print("è¨“ç·´ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        # è¨“ç·´å®Ÿè¡Œ
        logger.info(f"ğŸš€ è¨“ç·´é–‹å§‹: epochs={epochs}, batch_size={batch_size}, lr={learning_rate}")
        cloner.train_model(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        save_confirm = safe_input("ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ (Y/n): ", "y").strip().lower()
        if save_confirm != 'n':
            cloner.save_model()
            logger.success("ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        
        logger.complete_operation("å¯¾è©±å¼ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
        
    except ValueError as e:
        error = ModelError(f"å…¥åŠ›å€¤ã‚¨ãƒ©ãƒ¼: {e}")
        handle_error(error, severity=ErrorSeverity.MEDIUM)
    except Exception as e:
        error = ModelError(f"è¨“ç·´ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        handle_error(error, severity=ErrorSeverity.HIGH)

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼2: æ—¢å­˜ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# =============================================================================

def load_model_interactive(cloner):
    """å¯¾è©±å¼ã§ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’å®Ÿè¡Œï¼ˆç®¡ç†æ”¹å–„ç‰ˆï¼‰"""
    print("\n=== ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ===")
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
    models_path = Path("models")
    if models_path.exists():
        model_files = list(models_path.glob("*.pth"))
        if model_files:
            print("\nğŸ“ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«:")
            for i, model_file in enumerate(model_files, 1):
                file_size = model_file.stat().st_size / (1024 * 1024)  # MB
                modified = model_file.stat().st_mtime
                import datetime
                mod_time = datetime.datetime.fromtimestamp(modified).strftime('%Y-%m-%d %H:%M')
                print(f"  {i}. {model_file.name} ({file_size:.1f}MB, {mod_time})")
        else:
            print("\nâŒ models/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print("\nâŒ models/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ãƒã‚§ãƒƒã‚¯
    default_model = models_path / "voice_clone_model.pth"
    if default_model.exists():
        print(f"\nâœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«: {default_model.name}")
        use_default = safe_input("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ (Y/n): ", "y").strip().lower()
        if use_default != 'n':
            try:
                cloner.load_model(str(default_model))
                print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
                return
            except Exception as e:
                print(f"âŒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"\nâš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {default_model}")
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¹å…¥åŠ›
    model_path = safe_input("èª­ã¿è¾¼ã‚€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ› (ç©ºç™½ã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«): ", "").strip()
    if not model_path:
        print("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
        return
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Ÿè¡Œ
    try:
        if not Path(model_path).exists():
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
            return
            
        cloner.load_model(model_path)
        print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼3: éŸ³å£°åˆæˆ
# =============================================================================

@error_handler(severity=ErrorSeverity.HIGH, recovery=True)
def synthesize_speech_interactive(cloner):
    """å¯¾è©±å¼ã§éŸ³å£°åˆæˆã‚’å®Ÿè¡Œ"""
    if cloner.model is None:
        print("\nâŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        print("\nğŸ“‹ è§£æ±ºæ–¹æ³•:")
        print("  1. ãƒ¡ãƒ‹ãƒ¥ãƒ¼2ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€")
        print("  2. ãƒ¡ãƒ‹ãƒ¥ãƒ¼1ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹")
        
        # è‡ªå‹•çš„ã«ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’ææ¡ˆ
        auto_load = safe_input("\nè‡ªå‹•çš„ã«ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’è©¦è¡Œã—ã¾ã™ã‹ï¼Ÿ (Y/n): ", "y").strip().lower()
        if auto_load != 'n':
            load_model_interactive(cloner)
            
            # å†ãƒã‚§ãƒƒã‚¯
            if cloner.model is None:
                print("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return
            else:
                print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸã€éŸ³å£°åˆæˆã‚’ç¶šè¡Œã—ã¾ã™")
        else:
            return
    
    try:
        text = safe_input("åˆæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›: ", "ã“ã‚“ã«ã¡ã¯").strip()
        if not text:
            raise ValueError("ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        output_path = safe_input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆç©ºç™½ã§defaultï¼‰: ", "").strip()
        if not output_path:
            output_path = None
        
        logger.start_operation(f"éŸ³å£°åˆæˆ: '{text}'")
        cloner.synthesize_speech(text, output_path)
        logger.complete_operation("éŸ³å£°åˆæˆ")
        
    except Exception as e:
        error = AudioPipelineError(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        handle_error(error, severity=ErrorSeverity.HIGH)

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼4: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ï¼ˆæœªå®Ÿè£…ï¼‰
# =============================================================================

def add_new_data_interactive(cloner):
    """æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ï¼ˆä»Šå¾Œå®Ÿè£…äºˆå®šï¼‰"""
    print("ã“ã®æ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™ã€‚")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼5: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
# =============================================================================

def display_data_files(cloner):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤ºï¼ˆæ¤œè¨¼å¼·åŒ–ç‰ˆï¼‰"""
    audio_files, text_files = cloner.collect_data_files()
    print("\n=== æ¤œå‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« ===")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
    validation_results = validate_dataset_files(audio_files, text_files)
    
    if len(audio_files) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
        dataset_path = Path("dataset")
        audio_path = dataset_path / "audio_files"
        meta_path = dataset_path / "meta_files"
        
        print(f"\nãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªçŠ¶æ…‹:")
        print(f"  dataset/: {'âœ… å­˜åœ¨' if dataset_path.exists() else 'âŒ ä¸å­˜åœ¨'}")
        print(f"  audio_files/: {'âœ… å­˜åœ¨' if audio_path.exists() else 'âŒ ä¸å­˜åœ¨'}")
        print(f"  meta_files/: {'âœ… å­˜åœ¨' if meta_path.exists() else 'âŒ ä¸å­˜åœ¨'}")
        
        print("\næ­£ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :")
        print("dataset/")
        print("â”œâ”€â”€ audio_files/")
        print("â”‚   â”œâ”€â”€ audio_0001.wav")
        print("â”‚   â”œâ”€â”€ audio_0002.wav")
        print("â”‚   â””â”€â”€ ...")
        print("â””â”€â”€ meta_files/")
        print("    â”œâ”€â”€ audio_0001.txt")
        print("    â”œâ”€â”€ audio_0002.txt")
        print("    â””â”€â”€ ...")
        
        print("\nâ— ãƒ•ã‚¡ã‚¤ãƒ«åã¯å¿…ãš 'audio_NNNN.wav' ã¨ 'audio_NNNN.txt' ã®å½¢å¼ã§ã€")
        print("   NNNNã¯åŒã˜ç•ªå·ï¼ˆä¾‹: 0001ï¼‰ã«ã—ã¦ãã ã•ã„ã€‚")
    else:
        print(f"âœ“ {len(audio_files)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:\n")
        
        # æ¤œè¨¼çµæœã‚µãƒãƒªè¡¨ç¤º
        if validation_results:
            valid_count = sum(1 for r in validation_results if r['valid'])
            print(f"æ¤œè¨¼çµæœ: {valid_count}/{len(validation_results)} ãƒšã‚¢ãŒæœ‰åŠ¹\n")
        
        for i, (audio, text) in enumerate(zip(audio_files, text_files)):
            # æ¤œè¨¼çµæœã‚’åæ˜ 
            status_icon = "âœ…" if validation_results and i < len(validation_results) and validation_results[i]['valid'] else "âŒ"
            
            print(f"{status_icon} {i+1:2d}. Audio: {os.path.basename(audio)}")
            print(f"     Text:  {os.path.basename(text)}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨æ¤œè¨¼æƒ…å ±è¡¨ç¤º
            try:
                audio_size = os.path.getsize(audio) / 1024  # KB
                print(f"     Size:  {audio_size:.1f} KB")
                
                # æ¤œè¨¼è©³ç´°è¡¨ç¤º
                if validation_results and i < len(validation_results):
                    result = validation_results[i]
                    if not result['valid']:
                        for issue in result['issues']:
                            print(f"     âš ï¸  {issue}")
                            
            except Exception as e:
                print(f"     Size:  ä¸æ˜ ({e})")
            print()

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼6: ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤ºï¼ˆä¸Šè¨˜ã§å®šç¾©æ¸ˆã¿ï¼‰
# =============================================================================

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼7: å‰å‡¦ç†çµæœç¢ºèª
# =============================================================================

def display_preprocessing_results(cloner):
    """å‰å‡¦ç†çµæœã‚’è¡¨ç¤º"""
    processed_audio_dir = os.path.join(cloner.processed_path, "cleaned_audio")
    comparison_dir = os.path.join(cloner.processed_path, "comparison")
    audio_comparison_dir = os.path.join(comparison_dir, "audio_pairs")
    stages_dir = os.path.join(comparison_dir, "processing_stages")
    stats_file = os.path.join(cloner.processed_path, "preprocessing_stats.json")
    
    print("\n=== å‰å‡¦ç†çµæœ ===")
    
    # çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    if os.path.exists(stats_file):
        try:
            import json
            with open(stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)
            
            summary = stats["processing_summary"]
            print(f"å‡¦ç†æ—¥æ™‚: {summary['timestamp']}")
            print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {summary['total_files']}")
            print(f"å‡¦ç†æˆåŠŸ: {summary['processed_files']}")
            print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
            
            # è©³ç´°è¡¨ç¤º
            if safe_input("\nè©³ç´°ã‚’è¡¨ç¤ºã—ã¾ã™ã‹ï¼Ÿ (y/N): ", "n").strip().lower() == 'y':
                print("\n=== ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è©³ç´° ===")
                for detail in stats["file_details"]:
                    if "error" not in detail:
                        print(f"\n{detail['index']:2d}. {detail['original_file']}")
                        print(f"     ã‚µã‚¤ã‚º: {detail['original_size_kb']:.1f}KB â†’ {detail['processed_size_kb']:.1f}KB ({detail['size_reduction_percent']:+.1f}%)")
                        print(f"     é•·ã•:   {detail['original_duration_sec']:.2f}s â†’ {detail['processed_duration_sec']:.2f}s ({detail['duration_reduction_percent']:+.1f}%)")
                    else:
                        print(f"\n{detail['index']:2d}. {detail['original_file']} - {detail['error']}")
        
        except Exception as e:
            print(f"âŒ çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("âŒ å‰å‡¦ç†çµ±è¨ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ…å ±
    print(f"\n=== ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ« ===")
    
    # å‰å‡¦ç†æ¸ˆã¿éŸ³å£°
    if os.path.exists(processed_audio_dir):
        processed_files = [f for f in os.listdir(processed_audio_dir) if f.endswith('.wav')]
        print(f"ğŸ“ å‰å‡¦ç†æ¸ˆã¿éŸ³å£°: {len(processed_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"   å ´æ‰€: {processed_audio_dir}")
    else:
        print("âŒ å‰å‡¦ç†æ¸ˆã¿éŸ³å£°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æ¯”è¼ƒç”¨éŸ³å£°ãƒšã‚¢
    if os.path.exists(audio_comparison_dir):
        comparison_files = [f for f in os.listdir(audio_comparison_dir) if f.endswith('.wav')]
        original_files = [f for f in comparison_files if f.startswith('original_')]
        processed_files = [f for f in comparison_files if f.startswith('processed_')]
        print(f"ğŸ“ æ¯”è¼ƒç”¨éŸ³å£°ãƒšã‚¢: {len(original_files)}çµ„")
        print(f"   å ´æ‰€: {audio_comparison_dir}")
    else:
        print("âŒ æ¯”è¼ƒç”¨éŸ³å£°ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # å‡¦ç†æ®µéšåˆ¥éŸ³å£°
    if os.path.exists(stages_dir):
        stage_files = [f for f in os.listdir(stages_dir) if f.endswith('.wav')]
        print(f"ğŸ“ å‡¦ç†æ®µéšåˆ¥éŸ³å£°: {len(stage_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"   å ´æ‰€: {stages_dir}")
    else:
        print("âŒ å‡¦ç†æ®µéšåˆ¥éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æ¯”è¼ƒç”»åƒ
    if os.path.exists(comparison_dir):
        comparison_images = [f for f in os.listdir(comparison_dir) if f.endswith('.png')]
        print(f"ğŸ“ æ¯”è¼ƒç”»åƒ: {len(comparison_images)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"   å ´æ‰€: {comparison_dir}")
    else:
        print("âŒ æ¯”è¼ƒç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼8: ãƒ¢ãƒ‡ãƒ«ãƒ»éŸ³å£°åˆæˆè¨ºæ–­
# =============================================================================

def check_model_status(cloner):
    """ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°çŠ¶æ…‹ã‚’ç¢ºèª"""
    print("=== ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèª ===")
    
    # 1. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    model_path = os.path.join(cloner.models_path, "voice_clone_model.pth")
    print(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_path}")
    print(f"å­˜åœ¨: {os.path.exists(model_path)}")
    
    if os.path.exists(model_path):
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
            file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ç°¡æ˜“ç¢ºèª
            import torch
            checkpoint = torch.load(model_path, map_location='cpu')
            print(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚­ãƒ¼: {list(checkpoint.keys())}")
            
            if 'model_state_dict' in checkpoint:
                print("âœ“ model_state_dict ãŒå­˜åœ¨")
            else:
                print("âŒ model_state_dict ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
            if 'text_processor' in checkpoint:
                print("âœ“ text_processor ãŒå­˜åœ¨")
                
                # èªå½™ã®ç¢ºèª
                text_proc = checkpoint['text_processor']
                if hasattr(text_proc, 'vocab') and text_proc.vocab:
                    vocab = text_proc.vocab
                    print(f"âœ“ èªå½™ã‚µã‚¤ã‚º: {len(vocab)}")
                    
                    # èªå½™ã®å‹ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«è¡¨ç¤º
                    if isinstance(vocab, dict):
                        print(f"èªå½™ã‚µãƒ³ãƒ—ãƒ«: {list(vocab.keys())[:10]}")
                        print("èªå½™å‹: è¾æ›¸")
                    elif isinstance(vocab, set):
                        print(f"èªå½™ã‚µãƒ³ãƒ—ãƒ«: {list(vocab)[:10]}")
                        print("èªå½™å‹: ã‚»ãƒƒãƒˆ")
                    elif isinstance(vocab, list):
                        print(f"èªå½™ã‚µãƒ³ãƒ—ãƒ«: {vocab[:10]}")
                        print("èªå½™å‹: ãƒªã‚¹ãƒˆ")
                    else:
                        print(f"èªå½™å‹: {type(vocab)}")
                else:
                    print("âŒ èªå½™ãŒç©ºã¾ãŸã¯å­˜åœ¨ã—ã¾ã›ã‚“")
            else:
                print("âŒ text_processor ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 2. ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹
    print(f"\nç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«: {cloner.model}")
    print(f"ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µ: {cloner.text_processor}")
    
    if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
        vocab = cloner.text_processor.vocab
        print(f"ç¾åœ¨ã®èªå½™: {len(vocab)}å€‹")
        print(f"ç¾åœ¨ã®èªå½™å‹: {type(vocab)}")
    else:
        print("âŒ ç¾åœ¨ã®èªå½™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def diagnose_model_and_synthesis(cloner):
    """ãƒ¢ãƒ‡ãƒ«ã¨éŸ³å£°åˆæˆã®è¨ºæ–­"""
    print("=== ãƒ¢ãƒ‡ãƒ«è¨ºæ–­ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # 1. ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ç¢ºèª
    print("âœ“ ãƒ¢ãƒ‡ãƒ«ã¯èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™")
    
    # 2. èªå½™ã‚µã‚¤ã‚ºç¢ºèª
    if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
        vocab = cloner.text_processor.vocab
        vocab_size = len(vocab)
        print(f"èªå½™ã‚µã‚¤ã‚º: {vocab_size}")
        
        # èªå½™ã®å‹ã«å¿œã˜ã¦è¡¨ç¤º
        if isinstance(vocab, dict):
            print(f"ã‚µãƒ³ãƒ—ãƒ«èªå½™: {list(vocab.keys())[:10]}")
            print("èªå½™å½¢å¼: æ–‡å­—â†’IDè¾æ›¸")
        elif isinstance(vocab, set):
            vocab_list = list(vocab)
            print(f"ã‚µãƒ³ãƒ—ãƒ«èªå½™: {vocab_list[:10]}")
            print("èªå½™å½¢å¼: æ–‡å­—ã‚»ãƒƒãƒˆ")
            print("âš ï¸  èªå½™ãŒã‚»ãƒƒãƒˆå½¢å¼ã§ã™ã€‚è¾æ›¸å½¢å¼ã«å¤‰æ›ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“")
            try:
                test_dict = {char: i for i, char in enumerate(sorted(vocab))}
                print(f"å¤‰æ›ãƒ†ã‚¹ãƒˆæˆåŠŸ: {list(test_dict.items())[:5]}")
            except Exception as e:
                print(f"å¤‰æ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        elif isinstance(vocab, list):
            print(f"ã‚µãƒ³ãƒ—ãƒ«èªå½™: {vocab[:10]}")
            print("èªå½™å½¢å¼: æ–‡å­—ãƒªã‚¹ãƒˆ")
        else:
            print(f"èªå½™å½¢å¼: {type(vocab)}")
    else:
        print("âŒ èªå½™ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # 3. ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¢ºèª
    try:
        total_params = sum(p.numel() for p in cloner.model.parameters())
        trainable_params = sum(p.numel() for p in cloner.model.parameters() if p.requires_grad)
        print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        print(f"å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
    except Exception as e:
        print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
    print("\n=== å‡ºåŠ›ãƒ†ã‚¹ãƒˆ ===")
    test_text = "ãƒ†ã‚¹ãƒˆ"
    
    try:
        import torch
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•°å€¤ã«å¤‰æ›
        text_sequence = cloner.text_processor.text_to_sequence(test_text)
        text_tensor = torch.LongTensor(text_sequence).unsqueeze(0).to(cloner.device)
        text_lengths = torch.LongTensor([len(text_sequence)]).to(cloner.device)
        
        print(f"å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: '{test_text}'")
        print(f"å¤‰æ›å¾Œæ•°å€¤: {text_sequence}")
        print(f"ãƒ†ãƒ³ã‚½ãƒ«ã‚µã‚¤ã‚º: {text_tensor.shape}")
        
        # å¤‰æ›çµæœã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if all(x == 0 for x in text_sequence):
            print("âŒ è­¦å‘Š: å…¨ã¦0ã«å¤‰æ›ã•ã‚Œã¦ã„ã¾ã™ï¼ˆèªå½™ã®å•é¡Œã®å¯èƒ½æ€§ï¼‰")
        elif max(text_sequence) >= len(cloner.text_processor.vocab):
            print(f"âŒ è­¦å‘Š: èªå½™ã‚µã‚¤ã‚º({len(cloner.text_processor.vocab)})ã‚’è¶…ãˆã‚‹IDãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
        else:
            print("âœ“ ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã¯æ­£å¸¸ã«è¦‹ãˆã¾ã™")
        
        # ãƒ¢ãƒ‡ãƒ«æ¨è«–
        cloner.model.eval()
        with torch.no_grad():
            mel_outputs, stop_outputs = cloner.model(text_tensor, text_lengths)
        
        print(f"ãƒ¡ãƒ«å‡ºåŠ›ã‚µã‚¤ã‚º: {mel_outputs.shape}")
        print(f"ãƒ¡ãƒ«å‡ºåŠ›ã®ç¯„å›²: [{mel_outputs.min().item():.3f}, {mel_outputs.max().item():.3f}]")
        print(f"ãƒ¡ãƒ«å‡ºåŠ›ã®å¹³å‡: {mel_outputs.mean().item():.3f}")
        print(f"åœæ­¢ãƒˆãƒ¼ã‚¯ãƒ³: {stop_outputs.mean().item():.3f}")
        
        # å‡ºåŠ›ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
        if torch.all(mel_outputs == 0):
            print("âŒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å‡ºåŠ›ãŒå…¨ã¦0ã§ã™")
        elif mel_outputs.std() < 0.01:
            print("âŒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å‡ºåŠ›ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        else:
            print("âœ“ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å‡ºåŠ›ã¯æ­£å¸¸ã«è¦‹ãˆã¾ã™")
        
    except Exception as e:
        print(f"âŒ å‡ºåŠ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()

def diagnose_synthesis_process(cloner, text="ã“ã‚“ã«ã¡ã¯"):
    """éŸ³å£°åˆæˆãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°è¨ºæ–­"""
    print(f"\n=== éŸ³å£°åˆæˆãƒ—ãƒ­ã‚»ã‚¹è¨ºæ–­ ===")
    print(f"åˆæˆãƒ†ã‚­ã‚¹ãƒˆ: '{text}'")
    
    try:
        import torch
        import numpy as np
        
        # Step 1: ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
        text_sequence = cloner.text_processor.text_to_sequence(text)
        text_tensor = torch.LongTensor(text_sequence).unsqueeze(0).to(cloner.device)
        text_lengths = torch.LongTensor([len(text_sequence)]).to(cloner.device)
        
        print(f"âœ“ ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†å®Œäº†: {text_sequence}")
        
        # Step 2: ãƒ¢ãƒ‡ãƒ«æ¨è«–
        cloner.model.eval()
        with torch.no_grad():
            mel_outputs, stop_outputs = cloner.model(text_tensor, text_lengths)
        
        mel_spec = mel_outputs.squeeze(0).cpu()
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«æ¨è«–å®Œäº†: {mel_spec.shape}")
        print(f"  ãƒ¡ãƒ«ç¯„å›²: [{mel_spec.min():.3f}, {mel_spec.max():.3f}]")
        print(f"  ãƒ¡ãƒ«å¹³å‡: {mel_spec.mean():.3f}")
        print(f"  ãƒ¡ãƒ«æ¨™æº–åå·®: {mel_spec.std():.3f}")
        
        # Step 3: ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ
        print(f"\nå„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã®ãƒ†ã‚¹ãƒˆ:")
        
        # Griffin-Lim
        try:
            audio_griffin = cloner._griffin_lim_synthesis(mel_spec)
            print(f"âœ“ Griffin-Lim: {len(audio_griffin)} samples")
            print(f"  éŸ³å£°ç¯„å›²: [{audio_griffin.min():.6f}, {audio_griffin.max():.6f}]")
            print(f"  éŸ³å£°RMS: {torch.sqrt(torch.mean(audio_griffin**2)):.6f}")
        except Exception as e:
            print(f"âŒ Griffin-Lim ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ç°¡æ˜“ãƒœã‚³ãƒ¼ãƒ€ãƒ¼
        try:
            audio_simple = cloner._simple_vocoder(mel_spec)
            print(f"âœ“ ç°¡æ˜“ãƒœã‚³ãƒ¼ãƒ€ãƒ¼: {len(audio_simple)} samples")
            print(f"  éŸ³å£°ç¯„å›²: [{audio_simple.min():.6f}, {audio_simple.max():.6f}]")
            print(f"  éŸ³å£°RMS: {torch.sqrt(torch.mean(audio_simple**2)):.6f}")
        except Exception as e:
            print(f"âŒ ç°¡æ˜“ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼
        if hasattr(cloner, '_improved_vocoder'):
            try:
                audio_improved = cloner._improved_vocoder(mel_spec)
                print(f"âœ“ æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼: {len(audio_improved)} samples")
                print(f"  éŸ³å£°ç¯„å›²: [{audio_improved.min():.6f}, {audio_improved.max():.6f}]")
                print(f"  éŸ³å£°RMS: {torch.sqrt(torch.mean(audio_improved**2)):.6f}")
            except Exception as e:
                print(f"âŒ æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ ã‚¨ãƒ©ãƒ¼: {e}")
            
    except Exception as e:
        print(f"âŒ è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()

def force_load_model(cloner):
    """å¼·åˆ¶çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ç›´ã™"""
    print("=== å¼·åˆ¶ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ===")
    
    model_path = os.path.join(cloner.models_path, "voice_clone_model.pth")
    
    if not os.path.exists(model_path):
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        print("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ãã ã•ã„ï¼ˆãƒ¡ãƒ‹ãƒ¥ãƒ¼1ï¼‰")
        return False
    
    try:
        print("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        cloner.load_model(model_path)
        
        if cloner.model is not None:
            print("âœ“ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            
            if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
                print(f"âœ“ èªå½™èª­ã¿è¾¼ã¿æˆåŠŸ: {len(cloner.text_processor.vocab)}å€‹")
                
                test_text = "ã“ã‚“ã«ã¡ã¯"
                test_sequence = cloner.text_processor.text_to_sequence(test_text)
                print(f"ãƒ†ã‚¹ãƒˆå¤‰æ›: '{test_text}' â†’ {test_sequence}")
                
                if all(x == 0 for x in test_sequence):
                    print("âŒ ã¾ã ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ãŒæ­£å¸¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                    return False
                else:
                    print("âœ“ ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›æ­£å¸¸")
                    return True
            else:
                print("âŒ èªå½™ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
        else:
            print("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return False

def verify_training_data_and_retrain(cloner):
    """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦å¿…è¦ã«å¿œã˜ã¦å†è¨“ç·´"""
    print("=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç¢ºèª ===")
    
    audio_files, text_files = cloner.collect_data_files()
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢æ•°: {len(audio_files)}")
    
    if len(audio_files) == 0:
        print("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return False
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ç¢ºèª
    print("\nãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«:")
    for i in range(min(3, len(text_files))):
        try:
            with open(text_files[i], 'r', encoding='utf-8') as f:
                content = f.read().strip()
            print(f"  {i+1}. {os.path.basename(text_files[i])}: '{content[:30]}{'...' if len(content) > 30 else ''}'")
        except Exception as e:
            print(f"  {i+1}. {os.path.basename(text_files[i])}: ã‚¨ãƒ©ãƒ¼ - {e}")
    
    # å†è¨“ç·´ã®ææ¡ˆ
    retrain = safe_input(f"\n{len(audio_files)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ã—ã¾ã™ã‹ï¼Ÿ (y/N): ", "n").strip().lower()
    if retrain == 'y':
        print("å†è¨“ç·´ã‚’é–‹å§‹...")
        
        try:
            cloner.train_model(epochs=10, batch_size=1, learning_rate=0.001)
            cloner.save_model()
            print("âœ“ å†è¨“ç·´å®Œäº†")
            return True
        except Exception as e:
            print(f"âŒ å†è¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            return False
    
    return False

def model_synthesis_diagnosis_menu(cloner):
    """ãƒ¡ãƒ‹ãƒ¥ãƒ¼8: ãƒ¢ãƒ‡ãƒ«ãƒ»éŸ³å£°åˆæˆè¨ºæ–­ã®çµ±åˆãƒ¡ãƒ‹ãƒ¥ãƒ¼"""
    # ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèª
    check_model_status(cloner)
    
    # ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å ´åˆã®å¯¾å¿œ
    if cloner.model is None:
        print("\n=== ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¯¾å¿œ ===")
        print("1. æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åˆ¶èª­ã¿è¾¼ã¿")
        print("2. ãƒ‡ãƒ¼ã‚¿ç¢ºèªã¨å†è¨“ç·´")
        
        sub_choice = safe_input("é¸æŠ (1/2): ", "1").strip()
        
        if sub_choice == "1":
            if force_load_model(cloner):
                print("âœ“ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸã€è¨ºæ–­ã‚’ç¶šè¡Œ...")
                diagnose_model_and_synthesis(cloner)
                diagnose_synthesis_process(cloner)
            else:
                print("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
        
        elif sub_choice == "2":
            if verify_training_data_and_retrain(cloner):
                print("âœ“ å†è¨“ç·´å®Œäº†ã€è¨ºæ–­ã‚’ç¶šè¡Œ...")
                diagnose_model_and_synthesis(cloner)
                diagnose_synthesis_process(cloner)
            else:
                print("âŒ å†è¨“ç·´å¤±æ•—")
    else:
        # ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é€šå¸¸ã®è¨ºæ–­
        diagnose_model_and_synthesis(cloner)
        diagnose_synthesis_process(cloner)

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼9: ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆ
# =============================================================================

def generate_test_audio(cloner):
    """ãƒ†ã‚¹ãƒˆç”¨éŸ³å£°ã‚’ç”Ÿæˆ"""
    print("\n=== ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆ ===")
    
    import torch
    import torchaudio
    import numpy as np
    
    # 1. ç´”ç²‹ãªã‚µã‚¤ãƒ³æ³¢ãƒ†ã‚¹ãƒˆ
    print("1. ã‚µã‚¤ãƒ³æ³¢ãƒ†ã‚¹ãƒˆéŸ³å£°ã‚’ç”Ÿæˆ...")
    sample_rate = cloner.preprocessor.sample_rate
    duration = 2.0  # 2ç§’
    frequency = 440  # A4
    
    t = torch.linspace(0, duration, int(sample_rate * duration))
    sine_wave = 0.3 * torch.sin(2 * 3.14159 * frequency * t)
    
    test_path = os.path.join(cloner.output_path, "test_sine_wave.wav")
    torchaudio.save(test_path, sine_wave.unsqueeze(0), sample_rate)
    print(f"âœ“ ã‚µã‚¤ãƒ³æ³¢ä¿å­˜: {test_path}")
    
    # 2. ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®éŸ³å£°ç”Ÿæˆ
    print("2. ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ãƒ†ã‚¹ãƒˆ...")
    
    mel_frames = 100
    mel_bins = 80
    random_mel = torch.randn(mel_frames, mel_bins) * 0.5
    
    try:
        random_audio = cloner._simple_vocoder(random_mel)
        test_path2 = os.path.join(cloner.output_path, "test_random_mel.wav")
        torchaudio.save(test_path2, random_audio.unsqueeze(0), sample_rate)
        print(f"âœ“ ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«éŸ³å£°ä¿å­˜: {test_path2}")
        print(f"  éŸ³å£°é•·: {len(random_audio)/sample_rate:.2f}ç§’")
        print(f"  æœ€å¤§æŒ¯å¹…: {torch.max(torch.abs(random_audio)):.6f}")
    except Exception as e:
        print(f"âŒ ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®1ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
    print("3. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª...")
    
    audio_files, text_files = cloner.collect_data_files()
    if len(audio_files) > 0:
        sample_audio = cloner.preprocessor.load_audio(audio_files[0])
        if len(sample_audio) > 0:
            print(f"âœ“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«: {len(sample_audio)} samples")
            print(f"  æœ€å¤§æŒ¯å¹…: {np.max(np.abs(sample_audio)):.6f}")
            print(f"  RMS: {np.sqrt(np.mean(sample_audio**2)):.6f}")
            
            test_path3 = os.path.join(cloner.output_path, "test_training_sample.wav")
            torchaudio.save(test_path3, torch.from_numpy(sample_audio).unsqueeze(0), sample_rate)
            print(f"âœ“ å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«ä¿å­˜: {test_path3}")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼10: è©³ç´°ãƒ¢ãƒ‡ãƒ«è¨ºæ–­
# =============================================================================

def detailed_model_diagnosis(cloner):
    """è©³ç´°ãªãƒ¢ãƒ‡ãƒ«è¨ºæ–­"""
    print("=== è©³ç´°ãƒ¢ãƒ‡ãƒ«è¨ºæ–­ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    import torch
    import numpy as np
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±
    audio_files, text_files = cloner.collect_data_files()
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(audio_files)}å€‹")
    
    # 2. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®ç¢ºèª
    print("\n=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ« ===")
    for i in range(min(3, len(text_files))):
        try:
            with open(text_files[i], 'r', encoding='utf-8') as f:
                text_content = f.read().strip()
            
            sequence = cloner.text_processor.text_to_sequence(text_content)
            print(f"{i+1}. ãƒ†ã‚­ã‚¹ãƒˆ: '{text_content[:50]}...'")
            print(f"   å¤‰æ›çµæœ: {sequence[:10]}... (é•·ã•: {len(sequence)})")
            
            import torchaudio
            waveform, sample_rate = torchaudio.load(audio_files[i])
            duration = waveform.shape[1] / sample_rate
            print(f"   éŸ³å£°é•·: {duration:.2f}ç§’, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sample_rate}Hz")
            
        except Exception as e:
            print(f"{i+1}. ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. ãƒ¢ãƒ‡ãƒ«ã®å„å±¤ã®å‡ºåŠ›ç¢ºèª
    print("\n=== ãƒ¢ãƒ‡ãƒ«å±¤åˆ¥å‡ºåŠ›ç¢ºèª ===")
    test_text = "ãƒ†ã‚¹ãƒˆ"
    test_sequence = cloner.text_processor.text_to_sequence(test_text)
    test_tensor = torch.LongTensor(test_sequence).unsqueeze(0).to(cloner.device)
    test_lengths = torch.LongTensor([len(test_sequence)]).to(cloner.device)
    
    cloner.model.eval()
    with torch.no_grad():
        # åŸ‹ã‚è¾¼ã¿å±¤ã®å‡ºåŠ›
        embedded = cloner.model.embedding(test_tensor)
        print(f"åŸ‹ã‚è¾¼ã¿å‡ºåŠ›: {embedded.shape}, ç¯„å›²: [{embedded.min():.3f}, {embedded.max():.3f}]")
        
        # LSTMå‡ºåŠ›
        lstm_out, _ = cloner.model.text_lstm(embedded)
        print(f"LSTMå‡ºåŠ›: {lstm_out.shape}, ç¯„å›²: [{lstm_out.min():.3f}, {lstm_out.max():.3f}]")
        
        # æœ€çµ‚å‡ºåŠ›
        mel_outputs, stop_outputs = cloner.model(test_tensor, test_lengths)
        print(f"ãƒ¡ãƒ«å‡ºåŠ›: {mel_outputs.shape}, ç¯„å›²: [{mel_outputs.min():.3f}, {mel_outputs.max():.3f}]")
        print(f"åœæ­¢å‡ºåŠ›: {stop_outputs.shape}, ç¯„å›²: [{stop_outputs.min():.3f}, {stop_outputs.max():.3f}]")
        
        # ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®ç‰¹æ€§åˆ†æ
        mel_spec = mel_outputs.squeeze(0).cpu().numpy()
        print(f"\nãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ åˆ†æ:")
        print(f"  å¹³å‡: {np.mean(mel_spec):.3f}")
        print(f"  æ¨™æº–åå·®: {np.std(mel_spec):.3f}")
        print(f"  æœ€å°å€¤: {np.min(mel_spec):.3f}")
        print(f"  æœ€å¤§å€¤: {np.max(mel_spec):.3f}")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ã®å¤‰åŒ–
        frame_means = np.mean(mel_spec, axis=1)
        print(f"  ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å¤‰åŒ–: {np.std(frame_means):.3f}")
        if np.std(frame_means) < 0.1:
            print("  âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å¤‰åŒ–ãŒå°‘ãªã™ãã¾ã™ï¼ˆå˜èª¿ãªå‡ºåŠ›ï¼‰")
        
        # å‘¨æ³¢æ•°åˆ¥ã®å¤‰åŒ–
        freq_means = np.mean(mel_spec, axis=0)
        print(f"  å‘¨æ³¢æ•°é–“ã®å¤‰åŒ–: {np.std(freq_means):.3f}")
        if np.std(freq_means) < 0.1:
            print("  âš ï¸  å‘¨æ³¢æ•°é–“ã®å¤‰åŒ–ãŒå°‘ãªã™ãã¾ã™ï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´ä¸è¶³ï¼‰")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼11: æ”¹å–„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†è¨“ç·´
# =============================================================================

def retrain_with_better_parameters(cloner):
    """æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†è¨“ç·´"""
    print("=== æ”¹å–„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å†è¨“ç·´ ===")
    
    audio_files, text_files = cloner.collect_data_files()
    if len(audio_files) == 0:
        print("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(audio_files)}å€‹")
    
    # ã‚ˆã‚Šè‰¯ã„è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    epochs = 100
    batch_size = 2
    learning_rate = 0.0005
    
    print(f"è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
    print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"  å­¦ç¿’ç‡: {learning_rate}")
    
    confirm = safe_input("ã“ã®è¨­å®šã§å†è¨“ç·´ã—ã¾ã™ã‹ï¼Ÿ (y/N): ", "n").strip().lower()
    if confirm == 'y':
        try:
            cloner.train_model(
                epochs=epochs, 
                batch_size=batch_size, 
                learning_rate=learning_rate
            )
            cloner.save_model()
            print("âœ“ å†è¨“ç·´å®Œäº†")
            return True
        except Exception as e:
            print(f"âŒ å†è¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            return False
    
    return False

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼12: ãƒœã‚³ãƒ¼ãƒ€ãƒ¼å•é¡Œè¨ºæ–­
# =============================================================================

def diagnose_vocoder_issue(cloner):
    """ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã®å•é¡Œã‚’è©³ç´°è¨ºæ–­"""
    print("=== ãƒœã‚³ãƒ¼ãƒ€ãƒ¼å•é¡Œè¨ºæ–­ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    import torch
    import numpy as np
    import torchaudio
    import os
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆ
    test_text = "ã‚ã„ã†ãˆãŠ"
    test_sequence = cloner.text_processor.text_to_sequence(test_text)
    test_tensor = torch.LongTensor(test_sequence).unsqueeze(0).to(cloner.device)
    test_lengths = torch.LongTensor([len(test_sequence)]).to(cloner.device)
    
    cloner.model.eval()
    with torch.no_grad():
        mel_outputs, _ = cloner.model(test_tensor, test_lengths)
    
    mel_spec = mel_outputs.squeeze(0).cpu()
    
    # äººå·¥çš„ãªç†æƒ³çš„ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¨æ¯”è¼ƒ
    print("äººå·¥ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã§ãƒ†ã‚¹ãƒˆ:")
    
    # ç°¡å˜ãªæ­£å¼¦æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
    artificial_mel = np.zeros((50, 80))
    for i in range(50):
        for j in range(80):
            # ä½åŸŸã«å¼·ã„ä¿¡å·ã‚’é…ç½®
            if j < 20:
                artificial_mel[i, j] = -10 + 5 * np.sin(2 * np.pi * i / 10)
            elif j < 40:
                artificial_mel[i, j] = -20 + 3 * np.sin(2 * np.pi * i / 15)
            else:
                artificial_mel[i, j] = -30 + np.sin(2 * np.pi * i / 20)
    
    artificial_mel_tensor = torch.from_numpy(artificial_mel.astype(np.float32))
    
    # äººå·¥ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã§ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ
    try:
        artificial_audio = cloner._improved_vocoder(artificial_mel_tensor)
        print(f"âœ“ äººå·¥ãƒ¡ãƒ« â†’ éŸ³å£°å¤‰æ›æˆåŠŸ: {len(artificial_audio)} samples")
        print(f"  éŸ³å£°ç¯„å›²: [{artificial_audio.min():.3f}, {artificial_audio.max():.3f}]")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ç¢ºèª
        test_path = os.path.join(cloner.output_path, "test_artificial.wav")
        torchaudio.save(test_path, artificial_audio.unsqueeze(0), cloner.preprocessor.sample_rate)
        print(f"âœ“ ãƒ†ã‚¹ãƒˆéŸ³å£°ä¿å­˜: {test_path}")
        
    except Exception as e:
        print(f"âŒ äººå·¥ãƒ¡ãƒ«ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã§ãƒ†ã‚¹ãƒˆ
    try:
        model_audio = cloner._improved_vocoder(mel_spec)
        print(f"ãƒ¢ãƒ‡ãƒ«å‡ºåŠ› â†’ éŸ³å£°å¤‰æ›: {len(model_audio)} samples")
        print(f"  éŸ³å£°ç¯„å›²: [{model_audio.min():.3f}, {model_audio.max():.3f}]")
        
        # å®Ÿéš›ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ
        audio_files, _ = cloner.collect_data_files()
        if len(audio_files) > 0:
            original_audio, _ = torchaudio.load(audio_files[0])
            print(f"å…ƒéŸ³å£°ç¯„å›²: [{original_audio.min():.3f}, {original_audio.max():.3f}]")
            
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼13: ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£ï¼ˆæ–°è¦è¿½åŠ ï¼‰
# =============================================================================

def emergency_model_fix(cloner):
    """ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£"""
    print("=== ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    import torch
    
    # ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›é•·åˆ¶å¾¡ã‚’å¼·åˆ¶ä¿®æ­£
    original_forward = cloner.model.forward
    
    def fixed_forward(text_input, text_lengths, target_audio=None):
        # å…ƒã®å‡ºåŠ›ã‚’å–å¾—
        mel_outputs, stop_outputs = original_forward(text_input, text_lengths, target_audio)
        
        # å‡ºåŠ›ãŒçŸ­ã™ãã‚‹å ´åˆã¯å¼·åˆ¶å»¶é•·
        if mel_outputs.shape[1] < 20:  # 20ãƒ•ãƒ¬ãƒ¼ãƒ æœªæº€ã®å ´åˆ
            print(f"âš ï¸  å‡ºåŠ›ã‚’å¼·åˆ¶å»¶é•·: {mel_outputs.shape[1]} â†’ 50ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
            # æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç¹°ã‚Šè¿”ã—ã¦å»¶é•·
            last_frame = mel_outputs[:, -1:, :]
            repeat_count = 50 - mel_outputs.shape[1]
            
            # ã‚ãšã‹ãªãƒã‚¤ã‚ºã‚’è¿½åŠ ã—ã¦è‡ªç„¶ã«ã™ã‚‹
            noise = torch.randn_like(last_frame.repeat(1, repeat_count, 1)) * 0.5
            extended_frames = last_frame.repeat(1, repeat_count, 1) + noise
            
            mel_outputs = torch.cat([mel_outputs, extended_frames], dim=1)
            
            # åœæ­¢ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å»¶é•·
            stop_extension = torch.zeros(stop_outputs.shape[0], repeat_count, 1).to(stop_outputs.device)
            stop_outputs = torch.cat([stop_outputs, stop_extension], dim=1)
        
        return mel_outputs, stop_outputs
    
    # ãƒ¢ãƒ‡ãƒ«ã® forward ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç½®ãæ›ãˆ
    cloner.model.forward = fixed_forward
    
    print("âœ“ ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›é•·åˆ¶å¾¡ã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
    return True

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼142: å¤–éƒ¨ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ä½¿ç”¨è¨­å®šï¼ˆæ–°è¦è¿½åŠ ï¼‰
# =============================================================================

def use_external_vocoder(cloner):
    """å¤–éƒ¨ã®é«˜å“è³ªãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨"""
    print("=== é«˜å“è³ªãƒœã‚³ãƒ¼ãƒ€ãƒ¼è¨­å®š ===")
    print("1. æ”¹å–„ã•ã‚ŒãŸè‡ªä½œãƒœã‚³ãƒ¼ãƒ€ãƒ¼")
    print("2. WaveGlowï¼ˆå¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰")
    print("3. HiFi-GANï¼ˆæœ€é«˜å“è³ªï¼‰")
    
    choice = safe_input("é¸æŠ (1/2/3): ", "1").strip()
    
    if choice == "1":
        # ä¸Šè¨˜ã®_neural_vocoderã‚’ä½¿ç”¨
        print("âœ“ æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸ")
        return True
    elif choice == "2":
        print("WaveGlowã®çµ±åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™")
        return False
    elif choice == "3":
        print("HiFi-GANã®çµ±åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™")
        return False
    
    return False


def use_pretrained_approach(cloner):
    """äº‹å‰è¨“ç·´æ¸ˆã¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"""
    print("=== ç·Šæ€¥å¯¾å¿œãƒ¡ãƒ‹ãƒ¥ãƒ¼ ===")
    print("ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å‡ºåŠ›é•·ã®å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
    print("ä»¥ä¸‹ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™:")
    print()
    print("1. ç·Šæ€¥ä¿®æ­£ç‰ˆã§ç¶™ç¶šï¼ˆå³åº§ã«ä½¿ç”¨å¯èƒ½ï¼‰")
    print("2. é•·æ™‚é–“å†è¨“ç·´ï¼ˆ1-2æ™‚é–“ã€æ ¹æœ¬è§£æ±ºï¼‰")
    print("3. æˆ»ã‚‹")
    
    choice = safe_input("é¸æŠ (1/2/3): ", "1").strip()
    
    if choice == "1":
        return emergency_model_fix(cloner)
    elif choice == "2":
        return retrain_with_better_parameters(cloner)
    elif choice == "3":
        return False
    
    return False



# =============================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =============================================================================

def main():
    print("éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¸ã‚ˆã†ã“ã")
    
    # å¿…è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    ensure_directories()
    
    # ã‚¯ãƒ­ãƒ¼ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
    cloner = VoiceCloner()
    
    # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    if not check_dependencies():
        sys.exit(1)
    
    while True:
        # ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤ºï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ç•ªå·ï¼‰
        print("\n" + "="*50)
        print("ğŸ¤– AudioOpt - éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ")
        print("="*50)
        print("ğŸ“š ãƒ‡ãƒ¼ã‚¿ç®¡ç†:")
        print("  1.1 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
        print("  1.2 æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ")
        print("  1.3 ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª")
        print("ğŸ§  ãƒ¢ãƒ‡ãƒ«æ“ä½œ:")
        print("  2.1 æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿") 
        print("  2.2 ãƒ¢ãƒ‡ãƒ«ãƒ»éŸ³å£°åˆæˆè¨ºæ–­")
        print("  2.3 æ”¹å–„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†è¨“ç·´")
        print("ğŸµ éŸ³å£°ç”Ÿæˆ:")
        print("  3.1 éŸ³å£°åˆæˆ")
        print("  3.2 ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆ")
        print("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
        print("  4.1 ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º")
        print("  4.2 å‰å‡¦ç†çµæœç¢ºèª")
        print("ğŸš¨ è¨ºæ–­ãƒ»ä¿®æ­£:")
        print("  5.1 è©³ç´°ãƒ¢ãƒ‡ãƒ«è¨ºæ–­")
        print("  5.2 ãƒœã‚³ãƒ¼ãƒ€ãƒ¼å•é¡Œè¨ºæ–­")
        print("  5.3 ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£")
        print("  5.4 å¤–éƒ¨ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ä½¿ç”¨è¨­å®š")
        print("-" * 50)
        print("  0. çµ‚äº†")
        print("="*50)
        
        choice = safe_input("é¸æŠè‚¢ã‚’å…¥åŠ›: ", "0").strip()
        
        if choice == "0":
            print("ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
            break
        # ğŸ“š ãƒ‡ãƒ¼ã‚¿ç®¡ç†
        elif choice == "1.1" or choice == "1":
            train_model_interactive(cloner)
        elif choice == "1.2":
            add_new_data_interactive(cloner)
        elif choice == "1.3":
            display_data_files(cloner)
        # ğŸ§  ãƒ¢ãƒ‡ãƒ«æ“ä½œ
        elif choice == "2.1" or choice == "2":
            load_model_interactive(cloner)
        elif choice == "2.2":
            model_synthesis_diagnosis_menu(cloner)
        elif choice == "2.3":
            retrain_with_better_parameters(cloner)
        # ğŸµ éŸ³å£°ç”Ÿæˆ
        elif choice == "3.1" or choice == "3":
            synthesize_speech_interactive(cloner)
        elif choice == "3.2":
            generate_test_audio(cloner)
        # ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        elif choice == "4.1" or choice == "4":
            display_system_info(cloner)
        elif choice == "4.2":
            display_preprocessing_results(cloner)
        # ğŸš¨ è¨ºæ–­ãƒ»ä¿®æ­£
        elif choice == "5.1" or choice == "5":
            detailed_model_diagnosis(cloner)
        elif choice == "5.2":
            diagnose_vocoder_issue(cloner)
        elif choice == "5.3":
            use_pretrained_approach(cloner)
        elif choice == "5.4":
            use_external_vocoder(cloner)
        else:
            print("ç„¡åŠ¹ãªé¸æŠè‚¢ã§ã™ã€‚å†åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            print("ä¾‹: 1.1, 2.2, 3.1 ãªã©ã€ã¾ãŸã¯ 1, 2, 3 ã®çœç•¥å½¢ã‚‚å¯èƒ½")

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼é–¢æ•°ï¼ˆæ–°è¦è¿½åŠ ï¼‰
def validate_dataset_files(audio_files, text_files):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
    try:
        import soundfile as sf
    except ImportError:
        logger.warning("soundfileæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        sf = None
    
    validation_results = []
    
    for i, (audio_file, text_file) in enumerate(zip(audio_files, text_files)):
        result = {
            'index': i,
            'audio_file': audio_file,
            'text_file': text_file,
            'valid': True,
            'issues': []
        }
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        try:
            if not os.path.exists(audio_file):
                result['valid'] = False
                result['issues'].append("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„")
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                file_size = os.path.getsize(audio_file)
                if file_size < 1024:  # 1KBæœªæº€
                    result['valid'] = False
                    result['issues'].append(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå°ã•ã™ãã‚‹ ({file_size} bytes)")
                
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ãƒã‚§ãƒƒã‚¯ï¼ˆsoundfileåˆ©ç”¨å¯èƒ½æ™‚ï¼‰
                if sf:
                    try:
                        data, samplerate = sf.read(audio_file)
                        duration = len(data) / samplerate
                        
                        if duration < 0.5:  # 0.5ç§’æœªæº€
                            result['issues'].append(f"éŸ³å£°ãŒçŸ­ã™ãã‚‹ ({duration:.2f}ç§’)")
                        elif duration > 30:  # 30ç§’è¶…é
                            result['issues'].append(f"éŸ³å£°ãŒé•·ã™ãã‚‹ ({duration:.2f}ç§’)")
                            
                    except Exception as e:
                        result['valid'] = False
                        result['issues'].append(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æ: {str(e)[:50]}")
                    
        except Exception as e:
            result['valid'] = False
            result['issues'].append(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        try:
            if not os.path.exists(text_file):
                result['valid'] = False
                result['issues'].append("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„")
            else:
                with open(text_file, 'r', encoding='utf-8') as f:
                    text_content = f.read().strip()
                    
                if not text_content:
                    result['valid'] = False
                    result['issues'].append("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒç©º")
                elif len(text_content) < 3:
                    result['issues'].append(f"ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã‚‹ ({len(text_content)}æ–‡å­—)")
                elif len(text_content) > 200:
                    result['issues'].append(f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹ ({len(text_content)}æ–‡å­—)")
                    
        except Exception as e:
            result['valid'] = False
            result['issues'].append(f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}")
        
        validation_results.append(result)
    
    return validation_results

if __name__ == "__main__":
    main()