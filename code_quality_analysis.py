#!/usr/bin/env python3
"""
Audio Pipeline Integrated ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ
ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å„ªå…ˆé †ä½ã®æ±ºå®š
"""
import os
import ast
import re
from pathlib import Path
from collections import defaultdict, Counter

class CodeQualityAnalyzer:
    """ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_root="."):
        self.project_root = Path(project_root)
        self.issues = defaultdict(list)
        self.metrics = {}
        
    def analyze_project(self):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®åˆ†æ"""
        print("ğŸ” Audio Pipeline Integrated ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ")
        print("=" * 60)
        
        # Python ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        python_files = list(self.project_root.rglob("*.py"))
        self.metrics['total_files'] = len(python_files)
        
        print(f"ğŸ“ åˆ†æå¯¾è±¡: {len(python_files)} ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
        for py_file in python_files:
            if self._should_analyze(py_file):
                self.analyze_file(py_file)
        
        # å…¨ä½“ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        self.calculate_metrics()
        
        # çµæœè¡¨ç¤º
        self.display_results()
        
        # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å„ªå…ˆé †ä½
        self.prioritize_refactoring()
    
    def _should_analyze(self, file_path):
        """åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ¤å®š"""
        exclude_patterns = [
            '__pycache__',
            '.git',
            'test_',
            'setup.py',
            'migrate_',
            'analyze_',
        ]
        
        path_str = str(file_path)
        return not any(pattern in path_str for pattern in exclude_patterns)
    
    def analyze_file(self, file_path):
        """å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            lines = content.splitlines()
            self.metrics.setdefault('lines_of_code', 0)
            self.metrics['lines_of_code'] += len(lines)
            
            # ASTè§£æ
            try:
                tree = ast.parse(content)
                self.analyze_ast(tree, file_path)
            except SyntaxError as e:
                self.issues['syntax_errors'].append(f"{file_path}: {e}")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°åˆ†æ
            self.analyze_patterns(content, file_path)
            
        except Exception as e:
            self.issues['file_errors'].append(f"{file_path}: {e}")
    
    def analyze_ast(self, tree, file_path):
        """ASTï¼ˆæŠ½è±¡æ§‹æ–‡æœ¨ï¼‰åˆ†æ"""
        # é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹çµ±è¨ˆ
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                self.analyze_function(node, file_path)
            elif isinstance(node, ast.ClassDef):
                self.analyze_class(node, file_path)
            elif isinstance(node, ast.Import) or isinstance(node, ast.ImportFrom):
                self.analyze_import(node, file_path)
    
    def analyze_function(self, node, file_path):
        """é–¢æ•°åˆ†æ"""
        # é–¢æ•°ã®é•·ã•
        func_length = node.end_lineno - node.lineno if hasattr(node, 'end_lineno') else 0
        
        self.metrics.setdefault('functions', [])
        self.metrics['functions'].append({
            'name': node.name,
            'file': file_path,
            'length': func_length
        })
        
        # é•·ã™ãã‚‹é–¢æ•°
        if func_length > 50:
            self.issues['long_functions'].append(f"{file_path}:{node.name} ({func_length} lines)")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
        args_count = len(node.args.args)
        if args_count > 6:
            self.issues['too_many_params'].append(f"{file_path}:{node.name} ({args_count} params)")
    
    def analyze_class(self, node, file_path):
        """ã‚¯ãƒ©ã‚¹åˆ†æ"""
        self.metrics.setdefault('classes', [])
        self.metrics['classes'].append({
            'name': node.name,
            'file': file_path
        })
        
        # ãƒ¡ã‚½ãƒƒãƒ‰æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
        if len(methods) > 20:
            self.issues['large_classes'].append(f"{file_path}:{node.name} ({len(methods)} methods)")
    
    def analyze_import(self, node, file_path):
        """importåˆ†æ"""
        self.metrics.setdefault('imports', 0)
        self.metrics['imports'] += 1
        
        # ç›¸å¯¾import
        if isinstance(node, ast.ImportFrom) and node.level > 0:
            self.metrics.setdefault('relative_imports', 0)
            self.metrics['relative_imports'] += 1
    
    def analyze_patterns(self, content, file_path):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°åˆ†æ"""
        lines = content.splitlines()
        
        # å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        for i, line in enumerate(lines, 1):
            line_strip = line.strip()
            
            # é•·ã„è¡Œ
            if len(line) > 100:
                self.issues['long_lines'].append(f"{file_path}:{i}")
            
            # TODO/FIXME
            if re.search(r'#\s*(TODO|FIXME|HACK)', line, re.IGNORECASE):
                self.issues['todos'].append(f"{file_path}:{i}: {line_strip}")
            
            # printæ–‡ï¼ˆãƒ‡ãƒãƒƒã‚°æ®‹ã‚Šï¼‰
            if re.search(r'^\s*print\s*\(', line) and 'debug' not in line.lower():
                self.issues['debug_prints'].append(f"{file_path}:{i}")
            
            # é‡è¤‡ã‚³ãƒ¼ãƒ‰å€™è£œ
            if len(line_strip) > 30 and line_strip not in ['', '}', '{']:
                self.metrics.setdefault('code_lines', [])
                self.metrics['code_lines'].append(line_strip)
    
    def calculate_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        # è¤‡é›‘åº¦æŒ‡æ¨™
        if self.metrics.get('functions'):
            func_lengths = [f['length'] for f in self.metrics['functions']]
            self.metrics['avg_function_length'] = sum(func_lengths) / len(func_lengths)
            self.metrics['max_function_length'] = max(func_lengths)
        
        # é‡è¤‡ã‚³ãƒ¼ãƒ‰æ¤œå‡º
        if self.metrics.get('code_lines'):
            line_counts = Counter(self.metrics['code_lines'])
            duplicates = {line: count for line, count in line_counts.items() if count > 1}
            self.metrics['duplicate_lines'] = len(duplicates)
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–åº¦
        self.metrics['classes_per_file'] = len(self.metrics.get('classes', [])) / max(1, self.metrics['total_files'])
        self.metrics['functions_per_file'] = len(self.metrics.get('functions', [])) / max(1, self.metrics['total_files'])
    
    def display_results(self):
        """çµæœè¡¨ç¤º"""
        print("\nğŸ“Š ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 60)
        
        # åŸºæœ¬çµ±è¨ˆ
        print("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ:")
        print(f"  â€¢ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.metrics['total_files']}")
        print(f"  â€¢ ç·è¡Œæ•°: {self.metrics['lines_of_code']:,}")
        print(f"  â€¢ é–¢æ•°æ•°: {len(self.metrics.get('functions', []))}")
        print(f"  â€¢ ã‚¯ãƒ©ã‚¹æ•°: {len(self.metrics.get('classes', []))}")
        
        if self.metrics.get('avg_function_length'):
            print(f"  â€¢ å¹³å‡é–¢æ•°é•·: {self.metrics['avg_function_length']:.1f} è¡Œ")
        
        # å•é¡Œç‚¹
        print("\nâš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        total_issues = sum(len(issues) for issues in self.issues.values())
        print(f"  â€¢ ç·å•é¡Œæ•°: {total_issues}")
        
        for category, issues in self.issues.items():
            if issues:
                print(f"  â€¢ {category}: {len(issues)} ä»¶")
        
        # è©³ç´°å•é¡Œè¡¨ç¤ºï¼ˆé‡è¦ãªã‚‚ã®ã®ã¿ï¼‰
        if self.issues.get('long_functions'):
            print("\nğŸ” é•·ã™ãã‚‹é–¢æ•° (50è¡Œä»¥ä¸Š):")
            for func in self.issues['long_functions'][:5]:
                print(f"    {func}")
            if len(self.issues['long_functions']) > 5:
                print(f"    ... ä»– {len(self.issues['long_functions']) - 5} ä»¶")
        
        if self.issues.get('todos'):
            print("\nğŸ“ TODO/FIXME:")
            for todo in self.issues['todos'][:3]:
                print(f"    {todo}")
            if len(self.issues['todos']) > 3:
                print(f"    ... ä»– {len(self.issues['todos']) - 3} ä»¶")
    
    def prioritize_refactoring(self):
        """ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å„ªå…ˆé †ä½æ±ºå®š"""
        print("\nğŸ¯ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å„ªå…ˆé †ä½")
        print("=" * 60)
        
        priorities = []
        
        # é«˜å„ªå…ˆåº¦å•é¡Œ
        if self.issues.get('syntax_errors'):
            priorities.append(("ğŸš¨ ç·Šæ€¥", "æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ä¿®æ­£", len(self.issues['syntax_errors'])))
        
        if self.issues.get('long_functions'):
            priorities.append(("ğŸ”¥ é«˜", "é•·å¤§é–¢æ•°ã®åˆ†å‰²", len(self.issues['long_functions'])))
        
        if self.issues.get('large_classes'):
            priorities.append(("ğŸ”¥ é«˜", "å·¨å¤§ã‚¯ãƒ©ã‚¹ã®åˆ†å‰²", len(self.issues['large_classes'])))
        
        if self.metrics.get('duplicate_lines', 0) > 10:
            priorities.append(("ğŸ”¥ é«˜", "é‡è¤‡ã‚³ãƒ¼ãƒ‰ã®é™¤å»", self.metrics['duplicate_lines']))
        
        # ä¸­å„ªå…ˆåº¦å•é¡Œ
        if self.issues.get('too_many_params'):
            priorities.append(("âš ï¸ ä¸­", "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å‰Šæ¸›", len(self.issues['too_many_params'])))
        
        if self.issues.get('debug_prints'):
            priorities.append(("âš ï¸ ä¸­", "ãƒ‡ãƒãƒƒã‚°printæ–‡ã®é™¤å»", len(self.issues['debug_prints'])))
        
        if self.issues.get('long_lines'):
            priorities.append(("âš ï¸ ä¸­", "é•·ã„è¡Œã®åˆ†å‰²", len(self.issues['long_lines'])))
        
        # ä½å„ªå…ˆåº¦å•é¡Œ
        if self.issues.get('todos'):
            priorities.append(("ğŸ’¡ ä½", "TODO/FIXMEã®å¯¾å¿œ", len(self.issues['todos'])))
        
        # å„ªå…ˆé †ä½è¡¨ç¤º
        for priority, task, count in priorities:
            print(f"{priority} {task}: {count} ç®‡æ‰€")
        
        # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¨å¥¨é †åº
        print("\nğŸ“‹ æ¨å¥¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°é †åº:")
        refactor_plan = [
            "1. æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãƒ»é‡å¤§ãªå•é¡Œã®ä¿®æ­£",
            "2. é•·å¤§é–¢æ•°ã®åˆ†å‰²ï¼ˆ50è¡Œä»¥ä¸Š â†’ 20-30è¡Œï¼‰",
            "3. ã‚¯ãƒ©ã‚¹è¨­è¨ˆã®è¦‹ç›´ã—ï¼ˆå˜ä¸€è²¬ä»»åŸå‰‡ï¼‰",
            "4. é‡è¤‡ã‚³ãƒ¼ãƒ‰ã®å…±é€šåŒ–ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–",
            "5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®çµ±ä¸€ãƒ»å¼·åŒ–",
            "6. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ã‚³ãƒ¡ãƒ³ãƒˆã®æ•´å‚™",
            "7. ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®è¿½åŠ ãƒ»æ”¹å–„",
            "8. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"
        ]
        
        for step in refactor_plan:
            print(f"  {step}")
        
        # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°åŠ¹æœäºˆæ¸¬
        print(f"\nğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:")
        print(f"  â€¢ å¯èª­æ€§å‘ä¸Š: 60-80%")
        print(f"  â€¢ ä¿å®ˆæ€§å‘ä¸Š: 70-90%") 
        print(f"  â€¢ ãƒ‡ãƒãƒƒã‚°åŠ¹ç‡: 50-70%å‘ä¸Š")
        print(f"  â€¢ æ–°æ©Ÿèƒ½è¿½åŠ : 40-60%é«˜é€ŸåŒ–")
        print(f"  â€¢ macOSç§»è¡Œ: ã‚¹ãƒ ãƒ¼ã‚ºãªç§»è¡Œ")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    analyzer = CodeQualityAnalyzer()
    analyzer.analyze_project()
    
    print("\n" + "=" * 60)
    print("ğŸ’¡ çµè«–: MacBook Proç§»è¡Œå‰ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’å¼·ãæ¨å¥¨")
    print("ğŸ¯ ç¾ç’°å¢ƒã§ã‚³ãƒ¼ãƒ‰å“è³ªå‘ä¸Š â†’ ã‚¹ãƒ ãƒ¼ã‚ºãªç§»è¡Œ â†’ é«˜æ€§èƒ½åŒ–")

if __name__ == "__main__":
    main()