# Audio Pipeline Integrated - 統合音声処理システム

AI音声学習のためのエンドツーエンド音声処理パイプラインです。  
高品質な音声データセット作成から音声クローニング・音声合成まで、一つのプラットフォームで完結します。

## 🎯 概要

Audio Pipeline Integratedは、2つの専門システムを統合した包括的な音声処理ソリューションです：

- **Python_Audio_dataset**: 音声データセット録音・管理システム
- **AudioOpt**: 音声クローニング・音声合成システム
- **統合管理システム**: データ同期・ワークフロー自動化

## ✨ 主な特徴

### 🎙️ データセット録音（Python_Audio_dataset）
- **高品質録音**: 44.1kHz/16bit WAVファイル
- **台本管理**: 複数テキストファイル対応
- **進捗管理**: リアルタイム録音進捗表示
- **セッション保存**: 作業中断・再開機能
- **柔軟なナビゲーション**: 任意行へのジャンプ録音

### 🤖 音声クローニング（AudioOpt）
- **エンドツーエンド音声合成**: テキストから音声生成
- **日本語特化**: 五十音対応ボコーダー
- **高品質出力**: メル正規化完璧制御
- **複数ボコーダー**: 確実動作・五十音対応・フォールバック
- **GPU対応**: CUDA高速学習・推論

### 🔄 統合管理システム
- **自動データ同期**: プロジェクト間のシームレス連携
- **ワークフロー自動化**: 録音→前処理→学習→生成
- **統合ステータス管理**: 全体進捗の一元監視
- **データ整理機能**: 重複除去・最適化

## 🛠️ システム要件

### 必須環境
- **Python**: 3.8+
- **OS**: Windows 10+, macOS, Linux
- **RAM**: 4GB以上（推奨: 8GB+）
- **ストレージ**: 5GB以上の空き容量

### 推奨環境
- **GPU**: CUDA対応GPU（音声学習高速化）
- **マイク**: 高品質USBマイクまたはオーディオインターフェース
- **静音環境**: 録音品質向上のため

### 依存関係
```bash
# 録音・音声処理
sounddevice>=0.4.4
soundfile>=0.10.0
numpy>=1.20.0

# 機械学習・音声合成
torch>=1.12.0
torchaudio>=0.12.0
scipy>=1.9.0

# データ処理・可視化
matplotlib>=3.5.0
pathlib
json
```

## 📦 インストール

### 1. リポジトリのクローン
```bash
git clone https://github.com/yourusername/Audio_PipeLine_Integrated.git
cd Audio_PipeLine_Integrated
```

### 2. Conda環境の作成
```bash
conda create -n audio-pipeline python=3.10
conda activate audio-pipeline
```

### 3. 依存関係のインストール
```bash
# PyTorchとTorchaudio（CUDA対応）
conda install pytorch torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# 音声処理ライブラリ
conda install numpy matplotlib soundfile scipy -c conda-forge
pip install sounddevice
```

### 4. 音声デバイス確認
```bash
python Python_Audio_dataset/script/check_audio_devices.py
```

## 📁 プロジェクト構造

```
Audio_PipeLine_Integrated/
├── integrated_main.py              # 🎛️ 統合メインアプリケーション
├── shared_dataset_manager.py       # 🔄 データ同期システム
├── Python_Audio_dataset/           # 🎙️ 音声録音システム
│   ├── src/
│   │   ├── main.py                 # 録音メインアプリ
│   │   ├── text_manager.py         # テキスト・セッション管理
│   │   └── audio_recorder.py       # 音声録音・再生
│   ├── data/
│   │   ├── input/                  # 📄 原稿テキストファイル
│   │   └── session.json            # セッション状態（自動生成）
│   ├── dataset/                    # 📁 録音データ出力
│   │   ├── audio_files/            # 音声ファイル
│   │   ├── meta_files/             # テキストファイル
│   │   └── metadata.txt            # 統合メタデータ
│   ├── script/                     # 🔧 ユーティリティ
│   └── Reports/                    # 📋 開発レポート
├── AudioOpt/                       # 🤖 音声学習・生成システム
│   ├── src/
│   │   ├── audio/                  # 音声前処理
│   │   ├── text/                   # テキスト処理
│   │   ├── model/                  # モデル・データセット
│   │   └── core/                   # メインシステム
│   ├── dataset/                    # 📁 学習データ
│   │   ├── audio_files/            # 音声ファイル
│   │   ├── meta_files/             # メタファイル
│   │   ├── processed/              # 前処理データ
│   │   └── phoneme_data/           # 五十音データ
│   ├── models/                     # 🧠 訓練済みモデル
│   ├── output/                     # 🎵 合成音声出力
│   ├── Reports/                    # 📋 開発ログ
│   └── main.py                     # 音声合成メインアプリ
└── shared_dataset/                 # 🗂️ 統合データ領域
    ├── audio_files/                # 統合音声ファイル
    ├── meta_files/                 # 統合メタファイル
    ├── processed/                  # 処理済みデータ
    ├── phoneme_data/               # 五十音データ
    ├── backup/                     # バックアップ
    └── logs/                       # 同期ログ
```

## 🚀 使用方法

### 1. 統合システム起動

```bash
# 統合メインアプリケーション実行
python integrated_main.py
```

### 2. 統合メニュー

```
🎵 Audio Pipeline Integrated
====================================
1. 📚 データセット録音 (Python_Audio_dataset)
2. 🤖 音声学習・生成 (AudioOpt)
3. 🔄 データセット同期
4. 📊 統合ステータス確認
5. 🧹 データ整理・最適化
6. 🚪 終了
====================================
```

### 3. 基本ワークフロー

#### Phase 1: データセット録音
1. **メニュー「1」選択** → Python_Audio_dataset起動
2. **台本準備** → `Japanese.txt`などテキストファイル配置
3. **録音作業** → `r`コマンドで録音開始
4. **進捗確認** → リアルタイム進捗表示
5. **終了** → `q`コマンドで終了

#### Phase 2: 自動同期
- 録音終了時に自動的にデータ同期実行
- `shared_dataset/`に統合データ作成
- AudioOpt用データ形式に自動変換

#### Phase 3: 音声学習・生成
1. **メニュー「2」選択** → AudioOpt起動
2. **データセット前処理** → メニュー「1」
3. **モデル訓練** → 自動的に最適パラメータで学習
4. **音声合成** → メニュー「3」でテキストから音声生成

### 4. 録音操作（Python_Audio_dataset）

| コマンド | 機能 |
|---------|------|
| `r` | 🎙️ 録音開始/再開（3秒カウントダウン） |
| `p` | ⏸️ 録音一時停止 |
| `s` | ⏹️ 録音停止・保存 |
| `l` | 🔊 録音音声の再生確認 |
| `n` | ➡️ 次の台本へ移動 |
| `b` | ⬅️ 前の台本へ移動 |
| `j` | 🎯 指定行にジャンプ |
| `rf` | 🔄 テキストファイル再読み込み |
| `sync` | 🔄 セッション同期 |
| `q` | 🚪 終了 |

### 5. 音声合成操作（AudioOpt）

```
=== AudioOptメニュー ===
1. データセットの前処理とモデル訓練
2. 既存モデルの読み込み
3. 音声合成
4. 新しいデータの追加
5. データファイル確認
6. システム情報表示
7. 前処理結果確認
8. モデル・音声合成診断
9. テスト音声生成
10. 詳細モデル診断
0. 終了
```

## 🎵 技術仕様

### 録音設定（Python_Audio_dataset）
- **ファイル形式**: WAV
- **サンプルレート**: 44.1kHz（CD品質）
- **ビット深度**: 16-bit
- **チャンネル**: 1（モノラル）
- **命名規則**: `audio_0001.wav`, `audio_0002.wav`...

### 音声合成設定（AudioOpt）
- **サンプルレート**: 22050Hz（音声合成最適化）
- **メルスペクトログラム**: 80次元
- **正規化範囲**: [-4.000, 4.000]完璧制御
- **STFT設定**: n_fft=2048, hop_length=256
- **音声長制御**: 最小0.6秒、最大11.6秒

### データ形式統一
- **音声ファイル**: `audio_NNNN.wav`（4桁ゼロパディング）
- **メタファイル**: `meta_NNNN.txt`（対応するテキスト）
- **統合メタデータ**: `metadata.txt`（ファイル名|テキスト形式）

## 🔄 データ同期システム

### 自動同期フロー
```
Python_Audio_dataset → shared_dataset → AudioOpt
    (録音・保存)         (統合管理)      (学習・生成)
        ↓                   ↓              ↓
   audio_N.wav         統合データ        前処理済み
   meta_N.txt          重複除去         モデル学習
   metadata.txt        バックアップ      音声合成
```

### 同期機能
- **差分同期**: タイムスタンプベース効率的同期
- **重複検出**: MD5ハッシュによる重複ファイル検出
- **自動バックアップ**: 元データの安全保護
- **整合性チェック**: データ破損検出・修復

### 統合ステータス表示
```
📊 統合ステータス
==================================
🎙️ Python_Audio_dataset: 157 音声ファイル
🤖 AudioOpt: 157 音声ファイル
📁 Shared_dataset: 157 音声ファイル
✅ 全プロジェクト同期済み
💾 共有データサイズ: 890.5 MB
🕒 最終同期: 2025-06-14 15:30:42
==================================
```

## 🎯 音声品質・性能

### 録音品質管理
- **環境ノイズ**: 静音環境推奨（40dB以下）
- **マイク距離**: 20-30cm最適
- **音量レベル**: 自動ゲイン調整
- **一貫性**: セッション管理による品質統一

### 音声合成品質
- **音声認識度**: 従来の砂嵐音から明瞭な「あー」音へ大幅改善
- **音韻精度**: 五十音対応ボコーダーによる日本語最適化
- **音声長**: 0.6-11.6秒の自然な長さ制御
- **フォルマント**: 日本語話者特性反映

### パフォーマンス
```
データセット規模別学習時間（GPU使用時）
- 100サンプル: 約15-30分
- 500サンプル: 約30-60分
- 1000サンプル: 約60-120分

推奨データセット規模
- 最小: 30分録音（基本動作確認）
- 推奨: 60-120分（高品質合成）
- 最適: 3-5時間（プロレベル品質）
```

## 🔧 高度な機能

### 日本語音韻対応（AudioOpt）
- **五十音表サポート**: あ行～わ行の全音韻
- **音韻分類**: 破裂音、摩擦音、鼻音、気息音、流音、半母音
- **フォルマント合成**: 各音韻の特徴周波数
- **エネルギー分布**: メルスペクトログラムからの自動推定

### 確実動作システム
- **段階的フォールバック**: 五十音対応 → 確実動作 → フォールバック
- **エラー回復**: 自動的な代替処理選択
- **品質保証**: 最低限の音声品質保証

### データ管理機能
- **重複検出・除去**: 自動重複ファイル管理
- **バックアップ管理**: 定期的な自動バックアップ
- **ログ管理**: 詳細な操作履歴記録
- **統計情報**: 進捗・品質指標の可視化

## 🎌 日本語特化機能

### 五十音ボコーダー（AudioOpt）
```
あ行: あ、い、う、え、お (基本母音)
か行: か、き、く、け、こ (破裂音特性)
さ行: さ、し、す、せ、そ (摩擦音特性)
た行: た、ち、つ、て、と (破裂音特性)
な行: な、に、ぬ、ね、の (鼻音特性)
は行: は、ひ、ふ、へ、ほ (気息音特性)
ま行: ま、み、む、め、も (鼻音特性)
や行: や、ゆ、よ (半母音特性)
ら行: ら、り、る、れ、ろ (流音特性)
わ行: わ、を (半母音特性)
ん: 鼻音
```

### 日本語最適化台本
```
# 音素練習用（Python_Audio_dataset/data/input/Japanese.txt）
あ、い、う、え、お
か、き、く、け、こ
今日は良い天気です。
私は音声データセットを作成しています。
人工知能の学習に使用される音声データです。
```

## 🔍 トラブルシューティング

### よくある問題と解決法

#### 1. 音声デバイス問題
```bash
# デバイス確認
python Python_Audio_dataset/script/check_audio_devices.py

# sounddevice再インストール
pip uninstall sounddevice
pip install sounddevice
```

#### 2. 録音コマンド無効
- **統合アプリ**: `integrated_main.py`から起動
- **直接起動**: `python Python_Audio_dataset/src/main.py`
- **状態リセット**: `rf`コマンドでテキスト再読み込み

#### 3. 同期問題
```bash
# 手動同期実行
python integrated_main.py
# メニュー「3」で同期実行
```

#### 4. AudioOpt学習失敗
- **メニュー13**: 緊急モデル修正実行
- **メニュー12**: ボコーダー問題診断
- **データ確認**: 音声ファイル17個以上推奨

#### 5. 合成音声品質問題
- **五十音対応**: 自動的に日本語最適化
- **確実動作**: フォールバック機能で最低品質保証
- **診断機能**: 詳細品質分析実行

### パフォーマンス最適化
```bash
# GPU使用確認
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

# メモリ使用量確認
python integrated_main.py
# メニュー「4」でシステム情報確認
```

## 📊 統合レポート・ログ

### 開発レポート
- **Python_Audio_dataset/Reports/**: 録音システム開発ログ
- **AudioOpt/Reports/**: 音声合成システム開発ログ
- **shared_dataset/logs/**: 統合システム運用ログ

### 統計情報
```
2025-06-14 統合実績
========================
🎙️ 録音データ: 157ファイル (89.5MB)
🤖 学習済みモデル: 1個 (245MB)
🎵 合成音声: 23ファイル (12.3MB)
⏱️ 総処理時間: 2時間15分
📈 音声品質: 砂嵐 → 明瞭音声へ大幅改善
```

## 🛣️ 今後の開発計画

### Phase 1: 基盤強化（完了✅）
- [x] 基本統合システム構築
- [x] データ同期システム実装
- [x] エラーハンドリング強化
- [x] 音声品質改善

### Phase 2: 機能拡張（進行中🔄）
- [ ] リアルタイム音声合成
- [ ] Webインターフェース開発
- [ ] 外部ボコーダー統合（HiFi-GAN等）
- [ ] 多話者対応機能

### Phase 3: 高度化（計画中📋）
- [ ] 音声品質自動評価
- [ ] ニューラル音声変換
- [ ] 多言語対応（英語・中国語）
- [ ] クラウド連携機能

### Phase 4: 商用化準備（将来🚀）
- [ ] API公開
- [ ] Docker対応
- [ ] ライセンス最適化
- [ ] ドキュメント多言語化

## 🏆 技術的特徴・優位性

### 1. エンドツーエンド設計
- 録音から音声生成まで一気通貫
- データ形式自動統一
- ワークフロー自動化

### 2. 日本語特化最適化
- 五十音表完全対応
- 日本語音韻特性反映
- 文化的コンテキスト考慮

### 3. 品質保証システム
- 段階的フォールバック
- 自動品質診断
- エラー自動回復

### 4. スケーラブル設計
- モジュラー構成
- プラグイン対応
- 並列処理対応

## 📄 ライセンス

このプロジェクトはMITライセンスの下で公開されています。  
教育・研究目的での利用を推奨します。

## 🤝 コントリビューション

### 貢献方法
1. このリポジトリをフォーク
2. 新しいブランチを作成 (`git checkout -b feature/amazing-feature`)
3. 変更をコミット (`git commit -m 'Add amazing feature'`)
4. ブランチにプッシュ (`git push origin feature/amazing-feature`)
5. プルリクエストを作成

### 貢献ガイドライン
- バグ報告は詳細な再現手順を含める
- 新機能提案は用途・効果を明確に記述
- コードは既存スタイルに合わせる
- テストコードを含める

## 🙏 謝辞

- **PyTorchチーム**: 深層学習フレームワーク
- **Torchaudioチーム**: 音声処理ライブラリ
- **音声処理コミュニティ**: 技術的知見・ベストプラクティス
- **オープンソースコミュニティ**: 様々なライブラリ・ツール

## 📞 お問い合わせ

**Email**: t.miyakawa244@gmail.com  
**GitHub Issues**: バグ報告・機能要望  
**Discussions**: 技術相談・質問

---

## 🔗 関連リンク

- **PyTorch**: https://pytorch.org/
- **Torchaudio**: https://pytorch.org/audio/
- **SoundDevice**: https://python-sounddevice.readthedocs.io/
- **SoundFile**: https://pysoundfile.readthedocs.io/

---

⭐ **このプロジェクトが役に立った場合は、スターを付けていただけると嬉しいです！**

**🎵 録音から音声生成まで、Audio Pipeline Integratedで全てが可能に！**  
**🇯🇵 日本語に特化した、次世代音声処理システム**

---

**最終更新**: 2025年6月14日  
**バージョン**: 1.0.0-integrated  
**ステータス**: 基本機能完成 ✅ | 統合テスト完了 ✅ | 商用準備中

# Shared Dataset Directory

このディレクトリは、Audio Pipeline Integratedプロジェクトの統合データ領域です。

## ディレクトリ構造

```
shared_dataset/
├── audio_files/        # 統合音声ファイル (.wav)
├── meta_files/         # 統合メタファイル (.txt)
├── processed/          # 前処理済みデータ
├── phoneme_data/       # 五十音データ
├── backup/             # バックアップデータ
└── logs/              # 同期・処理ログ
```

## 注意事項

- **このディレクトリの実際のデータファイルはGitで管理されません**
- **ディレクトリ構造のみが共有されます**
- データファイルは`shared_dataset_manager.py`によって自動生成されます

## データの生成方法

1. **統合システム起動**:
   ```bash
   python integrated_main.py
   ```

2. **データ同期実行**:
   - メニュー「3」でデータセット同期
   - 自動的にこのディレクトリ構造にデータが配置されます

## 管理対象外ファイル

以下のファイルタイプは`.gitignore`によって除外されます：
- `*.wav` - 音声ファイル
- `*.mp3` - 音声ファイル
- `*.log` - ログファイル
- `*.json` - セッションファイル
- その他の一時ファイル・キャッシュファイル

---

**注意**: プライベートな音声データを含むため、実ファイルは共有されません。