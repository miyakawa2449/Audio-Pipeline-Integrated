import os
import shutil
import json
from pathlib import Path
from datetime import datetime
from common.logger import get_logger
from common.error_handler import error_handler, ErrorSeverity, handle_error
from common.exceptions import (
    AudioPipelineError, AudioFileError, SystemError
)

class SharedDatasetManager:
    def __init__(self):
        self.logger = get_logger("SharedDatasetManager")
        self.root_dir = Path(__file__).parent
        self.shared_dataset_dir = self.root_dir / "shared_dataset"
        self.python_dataset_dir = self.root_dir / "Python_Audio_dataset" / "dataset"
        self.audioopt_dataset_dir = self.root_dir / "AudioOpt" / "dataset"
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        self.log_file = self.shared_dataset_dir / "sync_log.txt"
    
    def setup_shared_directories(self):
        """å…±æœ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ"""
        directories = [
            self.shared_dataset_dir / "audio_files",
            self.shared_dataset_dir / "meta_files", 
            self.shared_dataset_dir / "processed",
            self.shared_dataset_dir / "phoneme_data",
            self.shared_dataset_dir / "backup",
            self.shared_dataset_dir / "logs"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
        
        self._log("å…±æœ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆã—ã¾ã—ãŸ")
        self.logger.success("å…±æœ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    @error_handler(severity=ErrorSeverity.MEDIUM, recovery=True)
    def sync_all_projects(self):
        """å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ãƒ¼ã‚¿åŒæœŸ"""
        self._log("=== å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŒæœŸé–‹å§‹ ===")
        
        try:
            # Python_Audio_dataset â†’ shared_dataset
            self.sync_from_python_audio()
            
            # shared_dataset â†’ AudioOpt
            self.sync_to_audioopt()
            
            # çµ±åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            self.create_integration_metadata()
            
            self._log("å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŒæœŸå®Œäº†")
            self.logger.complete_operation("å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŒæœŸ")
            
        except Exception as e:
            error_msg = f"åŒæœŸã‚¨ãƒ©ãƒ¼: {e}"
            self._log(error_msg)
            raise AudioPipelineError(error_msg)
    
    def sync_from_python_audio(self):
        """Python_Audio_datasetã‹ã‚‰shared_datasetã¸åŒæœŸ"""
        self._log("Python_Audio_dataset â†’ shared_dataset åŒæœŸé–‹å§‹")
        
        if not self.python_dataset_dir.exists():
            self.logger.warning("Python_Audio_dataset/dataset ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ
        audio_src = self.python_dataset_dir / "audio_files"
        audio_dst = self.shared_dataset_dir / "audio_files"
        
        if audio_src.exists():
            synced_count = self._sync_directory(audio_src, audio_dst, "*.wav")
            self.logger.audio_info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ: {synced_count} ä»¶")
            self._log(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ: {synced_count} ä»¶")
        
        # ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ
        meta_src = self.python_dataset_dir / "meta_files"
        meta_dst = self.shared_dataset_dir / "meta_files"
        
        if meta_src.exists():
            synced_count = self._sync_directory(meta_src, meta_dst, "*.txt")
            self.logger.info(f"ğŸ“ ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ: {synced_count} ä»¶")
            self._log(f"ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ: {synced_count} ä»¶")
        
        # metadata.txtåŒæœŸ
        metadata_src = self.python_dataset_dir / "metadata.txt"
        metadata_dst = self.shared_dataset_dir / "metadata.txt"
        
        if metadata_src.exists():
            shutil.copy2(metadata_src, metadata_dst)
            self.logger.success("metadata.txt åŒæœŸå®Œäº†")
            self._log("metadata.txt åŒæœŸå®Œäº†")
    
    def sync_to_audioopt(self):
        """shared_datasetã‹ã‚‰AudioOptã¸åŒæœŸ"""
        self._log("shared_dataset â†’ AudioOpt åŒæœŸé–‹å§‹")
        
        # AudioOptã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
        audioopt_dirs = [
            self.audioopt_dataset_dir / "audio_files",
            self.audioopt_dataset_dir / "meta_files",
            self.audioopt_dataset_dir / "processed"
        ]
        
        for directory in audioopt_dirs:
            directory.mkdir(parents=True, exist_ok=True)
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ
        audio_src = self.shared_dataset_dir / "audio_files"
        audio_dst = self.audioopt_dataset_dir / "audio_files"
        
        if audio_src.exists():
            synced_count = self._sync_directory(audio_src, audio_dst, "*.wav")
            self.logger.audio_info(f"AudioOptéŸ³å£°åŒæœŸ: {synced_count} ä»¶")
        
        # ãƒ¡ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸ
        meta_src = self.shared_dataset_dir / "meta_files"
        meta_dst = self.audioopt_dataset_dir / "meta_files"
        
        if meta_src.exists():
            synced_count = self._sync_directory(meta_src, meta_dst, "*.txt")
            self.logger.info(f"ğŸ“ AudioOptãƒ¡ã‚¿åŒæœŸ: {synced_count} ä»¶")
        
        # metadata.txtåŒæœŸ
        metadata_src = self.shared_dataset_dir / "metadata.txt"
        metadata_dst = self.audioopt_dataset_dir / "metadata.txt"
        
        if metadata_src.exists():
            shutil.copy2(metadata_src, metadata_dst)
            self.logger.success("AudioOpt metadata.txt åŒæœŸå®Œäº†")
        
        self.logger.complete_operation("AudioOpt ã¸ã®åŒæœŸ")
        self._log("AudioOpt ã¸ã®åŒæœŸå®Œäº†")
    
    def _sync_directory(self, src_dir, dst_dir, pattern):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŒæœŸï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        dst_dir.mkdir(parents=True, exist_ok=True)
        synced_count = 0
        
        for file_path in src_dir.glob(pattern):
            dst_file = dst_dir / file_path.name
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ã‹ã€æ›´æ–°ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã‚³ãƒ”ãƒ¼
            if not dst_file.exists() or file_path.stat().st_mtime > dst_file.stat().st_mtime:
                try:
                    shutil.copy2(file_path, dst_file)
                    synced_count += 1
                except Exception as e:
                    error_msg = f"ãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚¨ãƒ©ãƒ¼ {file_path}: {e}"
                    self._log(error_msg)
                    self.logger.warning(error_msg)
        
        return synced_count
    
    def create_integration_metadata(self):
        """çµ±åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ"""
        metadata_path = self.shared_dataset_dir / "integration_status.json"
        
        # å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°å–å¾—
        python_audio_count = len(list(self.python_dataset_dir.glob("audio_files/*.wav"))) if self.python_dataset_dir.exists() else 0
        audioopt_count = len(list(self.audioopt_dataset_dir.glob("audio_files/*.wav"))) if self.audioopt_dataset_dir.exists() else 0
        shared_count = len(list(self.shared_dataset_dir.glob("audio_files/*.wav")))
        
        status = {
            "last_sync": datetime.now().isoformat(),
            "file_counts": {
                "python_audio_dataset": python_audio_count,
                "audioopt": audioopt_count,
                "shared_dataset": shared_count
            },
            "directory_status": {
                "python_dataset_exists": self.python_dataset_dir.exists(),
                "audioopt_exists": self.audioopt_dataset_dir.exists(),
                "shared_dataset_exists": self.shared_dataset_dir.exists()
            },
            "sync_status": "completed" if python_audio_count == shared_count == audioopt_count else "partial"
        }
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(status, f, ensure_ascii=False, indent=2)
        
        self._log(f"çµ±åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°: {status}")
    
    def show_integration_status(self):
        """çµ±åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º"""
        print("\n" + "="*50)
        print("ğŸ“Š çµ±åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
        print("="*50)
        
        # å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ãƒ¼ã‚¿æ•°ç¢ºèª
        python_audio_count = len(list(self.python_dataset_dir.glob("audio_files/*.wav"))) if self.python_dataset_dir.exists() else 0
        audioopt_count = len(list(self.audioopt_dataset_dir.glob("audio_files/*.wav"))) if self.audioopt_dataset_dir.exists() else 0
        shared_count = len(list(self.shared_dataset_dir.glob("audio_files/*.wav")))
        
        print(f"ğŸ™ï¸ Python_Audio_dataset: {python_audio_count} éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"ğŸ¤– AudioOpt: {audioopt_count} éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"ğŸ“ Shared_dataset: {shared_count} éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # åŒæœŸçŠ¶æ³ç¢ºèª
        if python_audio_count > 0 and python_audio_count == shared_count == audioopt_count:
            print("âœ… å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŒæœŸæ¸ˆã¿")
        elif shared_count > 0:
            print("âš ï¸ éƒ¨åˆ†çš„ã«åŒæœŸæ¸ˆã¿ - å†åŒæœŸã‚’æ¨å¥¨")
        else:
            print("âŒ åŒæœŸãŒå¿…è¦ã§ã™")
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
        total_size = sum(f.stat().st_size for f in self.shared_dataset_dir.rglob('*') if f.is_file())
        print(f"ğŸ’¾ å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size / (1024*1024):.1f} MB")
        
        # æœ€æ–°åŒæœŸæ™‚åˆ»
        metadata_path = self.shared_dataset_dir / "integration_status.json"
        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                status = json.load(f)
                last_sync = status.get('last_sync', 'Unknown')
                print(f"ğŸ•’ æœ€çµ‚åŒæœŸ: {last_sync}")
        
        print("="*50)
    
    @error_handler(severity=ErrorSeverity.LOW, recovery=True)
    def cleanup_and_organize(self):
        """ãƒ‡ãƒ¼ã‚¿æ•´ç†ãƒ»æœ€é©åŒ–"""
        self.logger.start_operation("ãƒ‡ãƒ¼ã‚¿æ•´ç†")
        
        # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        duplicates = self._find_duplicate_files()
        if duplicates:
            self.logger.warning(f"é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(duplicates)} ä»¶")
            for dup in duplicates[:5]:  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
                self.logger.debug(f"   {dup}")
        
        # ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        empty_dirs = self._find_empty_directories()
        for empty_dir in empty_dirs:
            try:
                empty_dir.rmdir()
                self.logger.info(f"ğŸ—‘ï¸ ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤: {empty_dir}")
            except OSError:
                pass
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        self._rotate_log_files()
        
        self.logger.complete_operation("ãƒ‡ãƒ¼ã‚¿æ•´ç†")
    
    def _find_duplicate_files(self):
        """é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        import hashlib
        
        file_hashes = {}
        duplicates = []
        
        for file_path in self.shared_dataset_dir.rglob('*'):
            if file_path.is_file():
                try:
                    with open(file_path, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                    
                    if file_hash in file_hashes:
                        duplicates.append(f"{file_path} (duplicate of {file_hashes[file_hash]})")
                    else:
                        file_hashes[file_hash] = file_path
                except Exception:
                    continue
        
        return duplicates
    
    def _find_empty_directories(self):
        """ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œå‡º"""
        empty_dirs = []
        for dir_path in self.shared_dataset_dir.rglob('*'):
            if dir_path.is_dir() and not any(dir_path.iterdir()):
                empty_dirs.append(dir_path)
        return empty_dirs
    
    def _rotate_log_files(self):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        if self.log_file.exists() and self.log_file.stat().st_size > 1024 * 1024:  # 1MBä»¥ä¸Š
            backup_log = self.log_file.with_suffix('.txt.bak')
            shutil.move(self.log_file, backup_log)
            self.logger.info("ğŸ“‹ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã—ãŸ")
    
    def _log(self, message):
        """ãƒ­ã‚°è¨˜éŒ²"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {message}\n"
        
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(log_message)
        except Exception as e:
            # ãƒ­ã‚°æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆéã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ï¼‰
            self.logger.debug(f"ãƒ­ã‚°æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            pass